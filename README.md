# Interpretable Multimodal Thought-Partner AI

This repository implements a research prototype for a next-generation multimodal AI collaborator. It integrates natural language, visual, and code reasoning with interpretable outputs and plugin-based customization. Designed for scientific co-thinking tasks.

**Release Timeline:** Full model and benchmark suite planned for Q4 2025, with evaluation tools available Q3 2025.

## ðŸš€ Quickstart

```bash
pip install -r requirements.txt
python src/main.py
```

## ðŸ““ Colab Demo

[Live Notebook](https://colab.research.google.com/github/connorlango/thought-partner-ai/blob/main/demo.ipynb)

## ðŸ“„ Paper

See [docs/paper.md](./docs/paper.md)

## ðŸ§ª Benchmark

Evaluation tasks in [benchmarks/](./benchmarks/)

## ðŸ§  License

MIT
